{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT5170: Principles of ML - Assignment 2\n",
    "## Course code: 1MAO3\n",
    "### Participants (name: id): [ Daniel Verdejo: 22240224, Tom Cronin: < id >]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: DELETE THIS - ITS SOME BASIC INFORMATION AS A REFERENCE \n",
    "\n",
    "## Definition of the perceptron\n",
    "The perceptron is a linear-model binary classifier with a simple inputâ€”output relationship as depicted in Figure 2-3, which shows we're summing n number of inputs times their associated weights and then sending this \"net input\" to a step function with a defined threshold. Typically with perceptrons, this is a Heaviside step function with a threshold value of 0.5. This function will output a real-valued single binary value (0 or a 1), depending on the input.\n",
    "\n",
    "![perceptron](assets/perceptronFig.png?raw=true)\n",
    "\n",
    "We can model the decision boundary and the classification output in the Heaviside\n",
    "step function equation, as follows:\n",
    "\n",
    "![f of x](assets/fx.png)\n",
    "\n",
    "To produce the net input to the activation function (here, the Heaviside step function) we take the dot product of the input and the connection weights. We see this\n",
    "summation in the left half of Figure 2-3 as the input to the summation function.\n",
    "Table 2-1 provides an explanation of how the summation function is performed as\n",
    "well as notes about the parameters involved in the summation function.\n",
    "\n",
    "\n",
    "![params](assets/params.png)\n",
    "\n",
    "The output of the step function (activation function) is the output for the perceptron and gives us a classification of the input values. If the bias value is negative, it forces the learned weights sum to be a much greater value to get a 1 classification output. The bias term in this capacity moves the decision boundary around for the model. Input values do not affect the bias term, but the bias term is learned through the perceptron learning algorithm.\n",
    "\n",
    "## The perceptron learning algorithm\n",
    "The perceptron learning algorithm changes the weights in the perceptron model until all input records are all correctly classified. The algorithm will not terminate if the learning input is not linearly separable. A linearly separable dataset is one for which we can find the values of a hyperplane that will cleanly divide the two classes of the dataset.\n",
    "\n",
    "The perceptron learning algorithm initializes the weight vector with small random values or 0.0s at the beginning of training. The perceptron learning algorithm takes each input record, as we can see in Figure 2-3, and computes the output classification to check against the actual classification label. To produce the classification, the columns (features) are matched up to weights where n is the number of dimensions in both our input and weights. The first input value is the bias input, which is always 1.0 because we don't affect the bias input. The first weight is our bias term in this diagram. The dot product of the input vector and the weight vector gives us the input to our activation function, as we've previously discussed.\n",
    "\n",
    "If the classification is correct, no weight changes are made. If the classification is incorrect, the weights are adjusted accordingly. Weights are updated between individual training examples in an \"online learning\" fashion. This loop continues until all of the input examples are correctly classified. If the dataset is not linearly separable, the training algorithm will not terminate. Figure 2-4 demonstrates a dataset that is not linearly separable, the XOR logic function.\n",
    "\n",
    "![xor](assets/xor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import doctest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "def read_data_return_dataframe(PathToFile):\n",
    "    \"\"\"\n",
    "    Should return a dataframe of the test file\n",
    "    >>> type(read_data_return_dataframe('testdata.txt'))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "     Should have correct data in the dataframe.\n",
    "     There should be 20 entrys in the dataframe excluding of the column names\n",
    "    >>> read_data_return_dataframe('testdata.txt').size\n",
    "    20\n",
    "    \"\"\"\n",
    "    return pd.read_table(PathToFile) # reads txt file and converts it to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    type(read_data_return_dataframe('testdata.txt'))\n",
      "Expecting:\n",
      "    <class 'pandas.core.frame.DataFrame'>\n",
      "ok\n",
      "Trying:\n",
      "    read_data_return_dataframe('testdata.txt').size\n",
      "Expecting:\n",
      "    20\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(read_data_return_dataframe, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Verdejo - split into labels and attributes\n",
    "def split_df_labels_attributes(df):\n",
    "    \"\"\" Split the dataframe into two by labels and attributes\n",
    "\n",
    "        Keyword arguments:\n",
    "        df -- A pandas dataframe type containing labels and attributes\n",
    "        label_col_name -- A string which contains the name of the label column. \n",
    "\n",
    "        Returns:\n",
    "        tuple -- (label: pd.DataFrame, attributes: pd.DataFrame)\n",
    "\n",
    "        Should output only the Label column\n",
    "        >>> labels, attrs = split_df_labels_attributes(read_data_return_dataframe('testdata.txt'))\n",
    "        >>> labels\n",
    "                  Label\n",
    "                0  no   \n",
    "                1  no\n",
    "\n",
    "        Should not contain the Label column\n",
    "        >>> labels, attrs = split_df_labels_attributes(read_data_return_dataframe('testdata-alt.txt'))\n",
    "        >>> 'label' in attrs\n",
    "        False\n",
    "        \n",
    "        >>> attrs.columns\n",
    "        Index(['year', 'temp', 'humidity', 'rainfall', 'drought_code', 'buildup_index',\n",
    "          'day', 'month', 'wind_speed'],\n",
    "        dtype='object')\n",
    "      \"\"\"\n",
    "    return (df.iloc[:,0:1], df.iloc[:,1:])  # (for every row take columns upto index 1 exclusive, for every row take every column from 1 onwards inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    labels, attrs = split_df_labels_attributes(read_data_return_dataframe('testdata.txt'))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    labels\n",
      "Expecting:\n",
      "              Label\n",
      "            0  no   \n",
      "            1  no\n",
      "ok\n",
      "Trying:\n",
      "    labels, attrs = split_df_labels_attributes(read_data_return_dataframe('testdata-alt.txt'))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    'label' in attrs\n",
      "Expecting:\n",
      "    False\n",
      "ok\n",
      "Trying:\n",
      "    attrs.columns\n",
      "Expecting:\n",
      "    Index(['year', 'temp', 'humidity', 'rainfall', 'drought_code', 'buildup_index',\n",
      "      'day', 'month', 'wind_speed'],\n",
      "    dtype='object')\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(split_df_labels_attributes, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_23668\\4234067064.py:36: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  tr.values != te.values # te.index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daniel Verdejo - train, test splilt dataframe\n",
    "def split_df_to_train_test_dfs(df):\n",
    "    \"\"\" Splits a single dataframe into 2 dataframes\n",
    "    \n",
    "    Arguments:\n",
    "    df -- A pandas Dataframe to be split into 2\n",
    "\n",
    "    Returns:\n",
    "    tuple -- (df_train: pandas.Dataframe, df_test: pandas.Dataframe)\n",
    "    \n",
    "    Should split a single dataframe into 2 unique dataframes\n",
    "    >>> df = read_data_return_dataframe('wildfires.txt')\n",
    "    >>> train, test = split_df_to_train_test_dfs(df)\n",
    "    >>> train.index.equals(tr.index)\n",
    "    False\n",
    "\n",
    "    Length of train and test dataframes should equal the length of the orignal\n",
    "    >>> df = read_data_return_dataframe('wildfires.txt')\n",
    "    >>> train, test = split_df_to_train_test_dfs(df)\n",
    "    >>> len(train) + len(test) == len(df)\n",
    "    True\n",
    "\n",
    "    Should contain different values\n",
    "    >>> df = read_data_return_dataframe('wildfires.txt')\n",
    "    >>> train, test = split_df_to_train_test_dfs(df)\n",
    "    >>> train.values != test.values\n",
    "    True\n",
    "    \"\"\"\n",
    "    train_frac = round(np.random.uniform(.6, .7), 2) # get a random float for our training fraction\n",
    "    df_train = df.sample(frac = train_frac) # randomly sample a fraction of the dataframe between 60 & 70 % of its entirety\n",
    "    return (df_train,  df.drop(df_train.index)) # return the training data and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    df = read_data_return_dataframe('wildfires.txt')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    train, test = split_df_to_train_test_dfs(df)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    train.index.equals(tr.index)\n",
      "Expecting:\n",
      "    False\n",
      "ok\n",
      "Trying:\n",
      "    df = read_data_return_dataframe('wildfires.txt')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    train, test = split_df_to_train_test_dfs(df)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    len(train) + len(test) == len(df)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    df = read_data_return_dataframe('wildfires.txt')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    train, test = split_df_to_train_test_dfs(df)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    train.values != test.values\n",
      "Expecting:\n",
      "    True\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<doctest NoName[8]>:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  train.values != test.values\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(split_df_to_train_test_dfs, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  temp  humidity  rainfall  drought_code  buildup_index  day  month  \\\n",
      "0   2015    28        59       0.0          8.06           3.47    1      6   \n",
      "1   2010    30        61       1.3          8.17           4.03    2      6   \n",
      "2   2009    26        83      13.1          8.08           3.59    3      6   \n",
      "3   2017    25        87       2.5          7.18           2.42    4      6   \n",
      "4   2014    28        77       0.0         14.98           4.63    5      6   \n",
      "5   2008    30        67       0.0         22.71           7.97    6      6   \n",
      "6   2013    32        52       0.0         30.98          11.86    7      6   \n",
      "7   2009    29        72       0.0         38.66          14.31    8      6   \n",
      "8   2014    26        89       0.2         39.62          10.76    9      6   \n",
      "9   2007    28        77       0.0         46.44          13.14   10      6   \n",
      "10  2015    30        67       0.0         54.44          16.10   11      6   \n",
      "11  2009    26        81       0.0         61.80          18.33   12      6   \n",
      "12  2009    28        82       1.2         17.68           7.44   13      6   \n",
      "13  2011    31        80       0.5          7.98           4.53   14      6   \n",
      "14  2016    29        78       3.1          7.78           3.31   15      6   \n",
      "15  2010    30        88       0.7          7.93           2.92   16      6   \n",
      "16  2016    30        89       0.6          8.57           1.71   17      6   \n",
      "17  2011    30        78       0.3          8.31           2.44   18      6   \n",
      "18  2015    30        56       0.1         16.90           5.94   19      6   \n",
      "19  2008    29        80       0.4         27.73           5.38   20      6   \n",
      "20  2012    29        77       0.0         31.63           9.19   21      6   \n",
      "21  2010    30        69       0.1         39.89          10.52   22      6   \n",
      "22  2017    32        64       0.1         48.67          12.32   23      6   \n",
      "23  2007    32        66       0.0         56.41          15.86   24      6   \n",
      "24  2013    32        63       0.0         64.44          18.59   25      6   \n",
      "25  2011    30        62       0.0         72.51          22.26   26      6   \n",
      "26  2013    33        54       0.0         80.94          26.02   27      6   \n",
      "27  2009    33        55       0.0         88.58          30.49   28      6   \n",
      "28  2012    31        46       0.3         84.82          24.79   29      6   \n",
      "29  2015    32        50       0.0         93.22          29.17   30      6   \n",
      "30  2011    28        66       1.0          9.52           3.81    1      7   \n",
      "31  2017    28        77       1.2          9.06           3.25    2      7   \n",
      "32  2017    31        76       0.7         10.05           3.61    3      7   \n",
      "33  2015    33        78       0.0         19.46           6.40    4      7   \n",
      "34  2016    34        64       0.0         28.20           9.10    5      7   \n",
      "35  2017    32        61       0.0         37.33          13.06    6      7   \n",
      "36  2008    35        65       0.2         41.16          12.76    7      7   \n",
      "37  2007    33        69       0.0         50.56          15.43    8      7   \n",
      "38  2015    32        70       1.4         10.05           8.31    9      7   \n",
      "39  2007    33        67       0.7         10.23           6.00   10      7   \n",
      "\n",
      "    wind_speed  \n",
      "0           19  \n",
      "1           13  \n",
      "2           22  \n",
      "3           15  \n",
      "4           18  \n",
      "5           14  \n",
      "6           14  \n",
      "7           17  \n",
      "8           15  \n",
      "9           13  \n",
      "10          15  \n",
      "11          19  \n",
      "12          22  \n",
      "13          21  \n",
      "14          17  \n",
      "15          13  \n",
      "16          17  \n",
      "17          14  \n",
      "18          16  \n",
      "19          16  \n",
      "20          14  \n",
      "21          18  \n",
      "22          20  \n",
      "23          19  \n",
      "24          17  \n",
      "25          18  \n",
      "26          18  \n",
      "27          14  \n",
      "28          14  \n",
      "29          14  \n",
      "30          21  \n",
      "31          21  \n",
      "32          21  \n",
      "33          18  \n",
      "34          15  \n",
      "35          15  \n",
      "36          18  \n",
      "37          20  \n",
      "38          16  \n",
      "39          13  \n",
      "     year  temp  humidity  rainfall  drought_code  buildup_index  day  month  \\\n",
      "40   2012    34        74       0.0         18.95           8.94   11      7   \n",
      "41   2013    32        73       0.1         27.82          10.17   12      7   \n",
      "42   2008    35        79       0.0         38.08          12.44   13      7   \n",
      "43   2015    34        62       0.6         23.89           8.59   14      7   \n",
      "44   2012    30        81       0.4         17.22           6.27   15      7   \n",
      "..    ...   ...       ...       ...           ...            ...  ...    ...   \n",
      "199  2017    31        67       0.0         45.15          17.89   26      9   \n",
      "200  2017    29        89       4.4          8.74           6.52   27      9   \n",
      "201  2009    27        88       0.5          8.87           3.71   28      9   \n",
      "202  2016    25        56       0.1         15.54           6.10   29      9   \n",
      "203  2012    24        62       0.2         16.72           5.75   30      9   \n",
      "\n",
      "     wind_speed  \n",
      "40           15  \n",
      "41           15  \n",
      "42           16  \n",
      "43           14  \n",
      "44           19  \n",
      "..          ...  \n",
      "199          15  \n",
      "200          15  \n",
      "201          30  \n",
      "202          20  \n",
      "203          17  \n",
      "\n",
      "[164 rows x 9 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (164,9) and (8,) not aligned: 9 (dim 1) != 8 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danny\\dev\\machine-learning_CT5170\\POML_assignment2\\Assignment2.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m y \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39myes\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m x \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mto_numpy()[:,\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m P \u001b[39m=\u001b[39m Perceptron(\u001b[39m.05\u001b[39m, \u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mfit(X\u001b[39m.\u001b[39miloc[:\u001b[39m40\u001b[39m,\u001b[39m1\u001b[39m:], y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m P\u001b[39m.\u001b[39;49mpredict(X\u001b[39m.\u001b[39;49miloc[\u001b[39m40\u001b[39;49m:,\u001b[39m1\u001b[39;49m:])\n",
      "\u001b[1;32mc:\\Users\\danny\\dev\\machine-learning_CT5170\\POML_assignment2\\Assignment2.ipynb Cell 9\u001b[0m in \u001b[0;36mPerceptron.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mprint\u001b[39m(X)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     ln_out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_fn(ln_out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danny/dev/machine-learning_CT5170/POML_assignment2/Assignment2.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(pred)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (164,9) and (8,) not aligned: 9 (dim 1) != 8 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Daniel Verdejo - initial perceptron based on description above\n",
    "class Perceptron:\n",
    "\n",
    "    def __activation_fn__(x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def __init__(self, learn_rate, n_iters):\n",
    "        self.lr = learn_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_fn = (lambda x: np.where(x >= 0, 1, 0)) # TODO: might need to revisit this\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def __str__():\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(X)\n",
    "\n",
    "        if(isinstance(X, pd.DataFrame)):\n",
    "            X = X.to_numpy()[:,1:] # exclude the outcomes here will need to do this before \n",
    "        _, cnt_features = X.shape\n",
    "\n",
    "        self.weights = np.random.rand(cnt_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            for i, x_i in enumerate(X):\n",
    "                ln_out = np.dot(x_i, self.weights) + self.bias\n",
    "                pred = self.activation_fn(ln_out)\n",
    "                update = self.lr * (y[i] - pred)\n",
    "\n",
    "                self.weights = self.weights + (update * x_i)\n",
    "                self.bias += update\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(X)\n",
    "        ln_out = np.dot(X, self.weights) + self.bias\n",
    "        pred = self.activation_fn(ln_out)\n",
    "        print(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def fit_predict(self):\n",
    "        return self\n",
    "    \n",
    "    def evaluate(self):\n",
    "        pass\n",
    "\n",
    "# TODO: remove these when done testing! \n",
    "# X = read_data_return_dataframe(\"./wildfires.txt\")\n",
    "# y = [1 if \"yes\" in x else 0 for x in X.to_numpy()[:,0:1]]\n",
    "# P = Perceptron(.05, 5).fit(X.iloc[:40,1:], y)\n",
    "# P.predict(X.iloc[40:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c69e896b73d80df03b10aefe902562c227bdab9e6e1527e46fe261fc763f811"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
