{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CT5170: Principles of ML - Assignment 2\n",
    "## Course code: 1MAO3\n",
    "### Participants (name: id): (Daniel Verdejo: 22240224, Thomas Cronin: 22239435)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Utils'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pairplot\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mapp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mUtils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mapp\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mThresholdLogicUnit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ThresholdLogicUnit\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Perceptron\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "File \u001B[0;32m~/Workspace/masters/Assignments/principles_of_machine_learning/POML_assignment2/app/ThresholdLogicUnit.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mUtils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m e, \u001B[38;5;28mpow\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'Utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seaborn import pairplot\n",
    "from app.Utils import *\n",
    "\n",
    "from app.ThresholdLogicUnit import ThresholdLogicUnit\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "This section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "wildfires_df = read_data_return_dataframe(\"wildfires.txt\") # Loads The wildfire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "wildfires_df.shape # gets the dimensions of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "wildfires_df.columns # gets the features of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "wildfires_df.dtypes # returns the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "wildfires_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire Label\n",
    "The fire label seems to have 8 unique values for a table that should only have 2, yes or no. We can fix this by re-entering the fire label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = wildfires_df['fire'].copy()\n",
    "for index in range(len(ndarray)):\n",
    "    if 'no' in ndarray[index].lower():\n",
    "        ndarray[index] = \"NO\"\n",
    "    elif 'yes' in ndarray[index].lower():\n",
    "        ndarray[index] = \"YES\"\n",
    "wildfires_df['fire'] = ndarray\n",
    "labels_copy_df = wildfires_df['fire'].copy()\n",
    "wildfires_df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "# Lets Look at the data graphically\n",
    "wildfires_df.hist(figsize = (8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot = stripplot(x=\"fire\", y=\"fire\", data=wildfires_df, jitter=0.2, hue=\"fire\")\n",
    "features = ['year', 'temp', 'humidity', 'rainfall', 'drought_code','buildup_index', 'day', 'month', 'wind_speed'] # list of features wanted\n",
    "plot = pairplot(data=wildfires_df, hue=\"fire\", diag_kind=\"hist\", corner=True, height=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tom Cronin\n",
    "\n",
    "wildfires_df_normalised_copy = wildfires_df.copy()\n",
    "wildfires_features = wildfires_df[features].values # returns a numpy NdArray of the features\n",
    "wildfires_labels = wildfires_df[['fire']].values # returns a numpy NdArray of the label\n",
    "wildfires_features_normalise_copy = wildfires_df_normalised_copy[features].values # returns a numpy NdArray of the features\n",
    "wildfires_features_normalise_copy # Shows the features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires_features_normalised = Normalize(wildfires_features_normalise_copy, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires_features_normalised_df = pd.DataFrame(wildfires_features_normalised, columns=features)\n",
    "features = wildfires_features_normalised_df.copy()\n",
    "wildfires_features_normalised_df['fire'] = labels_copy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(data=wildfires_features_normalised_df, hue=\"fire\", diag_kind=\"hist\", corner=True, height=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wildfires_labels = convert_label(wildfires_labels, wildfires_df['fire'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, wildfires_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Single Perceptron Training and Tesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implemented Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel Verdejo - initial perceptron based on description above\n",
    "# TODO : Figure out if fit_predict and eval are needed ¯\\_(ツ)_/¯\n",
    "import src.perceptron as p\n",
    "import src.layer as l\n",
    "import src.mlp as nn\n",
    "from src.utils import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def transform(Y):\n",
    "    return np.array([1 if 'yes' in y else 0 for y in Y['fire']])\n",
    "\n",
    "# TODO: remove these when done testing! \n",
    " \n",
    "df = read_data_return_dataframe(\"./wildfires.txt\")\n",
    "y, X = split_df_labels_attributes(df)\n",
    "y = transform(y)\n",
    "y_test, X_test = split_df_labels_attributes(read_data_return_dataframe('./wildfires.txt'))\n",
    "y_test = transform(y_test)\n",
    "perc = p.Perceptron().fit(X, y)\n",
    "\n",
    "accuracy_score(y_test, perc.predict(X_test))\n",
    "\n",
    "l1 = l.Layer()\n",
    "l2 = [p.Perceptron() for _ in range(6)]\n",
    "mlp = nn.MLP(learn_rate=.02, n_iters= 500)\n",
    "# mlp.add_layer(l1)\n",
    "mlp.add_layer(l2)\n",
    "mlp.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "311f9ad72853ce38d00a12521a098bf105a13a75490bd1b1a64bc7cd30e01863"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
